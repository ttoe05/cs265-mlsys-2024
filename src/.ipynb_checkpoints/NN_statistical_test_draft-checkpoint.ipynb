{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Author: Terrill Toe\n",
    "The initial draft to the MLsystems project.\n",
    "\n",
    "The objective:\n",
    "\n",
    "Use a graph profiler construct a computational graph. The graph will encapsulate all the operations within an iteration of training a model. The nodes are individual operations and the edges will represent the dependencies of input and output data\n",
    "\n",
    "Deliverables:\n",
    "\n",
    "- [ ] Presentation containing the following \n",
    "    - [ ] Description of the intended design for the whole project\n",
    "    - [ ] pseudocode of each component with explanation.\n",
    "    - [ ] current progress\n",
    "    - [ ] experimental results obtained up to the midpoint\n",
    "- [ ] A design document describing the first phase of the project and experimental analysis that needs to be uploaded as a PDF on Canvas.\n",
    "    - [ ] design of the profiler\n",
    "    - [ ] pseudocode of each component with explanation.\n",
    "    - [ ] experimental analysis consisting of deliverables 4(a): Computation and memory profiling statistics and static analysis and 4(b) Peak memory consumption vs mini-batch size bar graph [w/o AC]. In general the experimental analysis on the document for each experiment should include a paragraph that describes each of the experiments, a paragraph that describes observations and a graph that demonstrates the results. When presenting, every experiment can be presented in a single slide using the graph and just enough textual info to understand the setup and results.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c3fedcf8d2fbba0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchbenchmark'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparallel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DistributedDataParallel \u001B[38;5;28;01mas\u001B[39;00m DDP\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgraph_prof\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GraphProfiler\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbenchmarks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Experiment\n",
      "File \u001B[0;32m~/Documents/Development/cs265-mlsys-2024/src/benchmarks.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchbenchmark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BenchmarkModel\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchbenchmark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hf_Bert, resnet50, resnet152\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m List, Dict, Any\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torchbenchmark'"
     ]
    }
   ],
   "source": [
    "# installs\n",
    "# !pip3 install chardet\n",
    "import numpy\n",
    "from copy import deepcopy\n",
    "from functools import wraps\n",
    "import os\n",
    "import logging\n",
    "import torch.multiprocessing as mp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.fx as fx\n",
    "from torch.fx.experimental.proxy_tensor import make_fx\n",
    "from torch.distributed._functional_collectives import all_reduce\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from graph_prof import GraphProfiler\n",
    "from benchmarks import Experiment\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T15:37:02.847754Z",
     "start_time": "2024-03-23T15:37:02.607416Z"
    }
   },
   "id": "b001fc0c39a2f62a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The TTModel for testing of graph profilers\n",
    "    \"\"\"\n",
    "    def __init__(self, layers: int, dim: int):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        for _ in range(layers):\n",
    "            modules.extend([nn.Linear(dim, dim), nn.ReLU()])\n",
    "        self.mod = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mod(x)\n",
    "    \n",
    "def training_step(\n",
    "        model: torch.nn.Module, optim: torch.optim.Optimizer, batch: torch.Tensor\n",
    "):\n",
    "    out: torch.Tensor = model(batch)\n",
    "    out.sum().backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    \n",
    "def run_worker(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "    logging.getLogger().setLevel(logging.DEBUG if rank == 0 else logging.CRITICAL)\n",
    "    if torch.backends.mps.is_available():\n",
    "        logging.info(f\"Torch MPS is available for this MacOS device\")\n",
    "    else:\n",
    "        raise ValueError(f\"Torch MPS is not available for this MacOS\")\n",
    "    if rank is None or world_size is None:\n",
    "        dist.init_process_group(backend=\"nccl\")\n",
    "    # else:\n",
    "    #     # dist.init_process_group(backend=\"gloo\", rank=rank, world_size=world_size)\n",
    "    logging.info(f\"Number of visisble devices: {torch.cuda.device_count()}\")\n",
    "    # set the device to mps instead of cuda\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    # torch.cuda.set_device(rank)\n",
    "    torch.manual_seed(20)\n",
    "    batch_size = 100\n",
    "    layers = 10\n",
    "    dim = 100\n",
    "    num_iters = 5\n",
    "    model = TTModel(layers, dim).to(mps_device)\n",
    "    batch = torch.randn(batch_size, dim).to(mps_device)\n",
    "    optim = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.01, foreach=False, fused=False, capturable=True\n",
    "    )\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            param.register_hook(all_reduce)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:00:37.358550Z",
     "start_time": "2024-03-17T16:00:37.355739Z"
    }
   },
   "id": "cbc8faf07e1a3745",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.current_device()\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:00:40.929754Z",
     "start_time": "2024-03-17T16:00:40.712518Z"
    }
   },
   "id": "8ecdd5ed9338f788",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if the backend is set up on the mac\n",
    "print(torch.backends.mps.is_available()) #the MacOS is higher than 12.3+\n",
    "print(torch.backends.mps.is_built()) #MPS is activated\n",
    "print(torch.backends.mps.is_macos13_or_newer())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:00:43.450457Z",
     "start_time": "2024-03-17T16:00:43.448071Z"
    }
   },
   "id": "1c13e0da487e96c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# run the worker to check the model can train\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m rank \u001B[38;5;241m=\u001B[39m \u001B[43mdist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_rank\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m world_size \u001B[38;5;241m=\u001B[39m dist\u001B[38;5;241m.\u001B[39mget_world_size()\n\u001B[1;32m      4\u001B[0m run_worker(rank, world_size)\n",
      "File \u001B[0;32m~/.pyenv/versions/cs265/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:1532\u001B[0m, in \u001B[0;36mget_rank\u001B[0;34m(group)\u001B[0m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _rank_not_in_group(group):\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1532\u001B[0m default_pg \u001B[38;5;241m=\u001B[39m \u001B[43m_get_default_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1533\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m group \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m group \u001B[38;5;129;01mis\u001B[39;00m GroupMember\u001B[38;5;241m.\u001B[39mWORLD:\n\u001B[1;32m   1534\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default_pg\u001B[38;5;241m.\u001B[39mrank()\n",
      "File \u001B[0;32m~/.pyenv/versions/cs265/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py:977\u001B[0m, in \u001B[0;36m_get_default_group\u001B[0;34m()\u001B[0m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the default process group created by init_process_group.\"\"\"\u001B[39;00m\n\u001B[1;32m    976\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_initialized():\n\u001B[0;32m--> 977\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    978\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDefault process group has not been initialized, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    979\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease make sure to call init_process_group.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    980\u001B[0m     )\n\u001B[1;32m    981\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m GroupMember\u001B[38;5;241m.\u001B[39mWORLD\n",
      "\u001B[0;31mValueError\u001B[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "# run the worker to check the model can train\n",
    "rank = dist.get_rank()\n",
    "world_size = dist.get_world_size()\n",
    "run_worker(rank, world_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:00:46.488392Z",
     "start_time": "2024-03-17T16:00:46.264442Z"
    }
   },
   "id": "dfdb6d704d4219fc",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.fx.graph_module.GraphModule.__new__.<locals>.GraphModuleImpl'>\n"
     ]
    }
   ],
   "source": [
    "# create a graph profiler of the model\n",
    "layers = 10\n",
    "dim = 100\n",
    "num_iters = 5\n",
    "model = TTModel(layers, dim).to(mps_device)\n",
    "TT_nn_graph = fx.symbolic_trace(model)\n",
    "print(type(TT_nn_graph))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:01:23.427008Z",
     "start_time": "2024-03-17T16:01:23.414102Z"
    }
   },
   "id": "30ffc857cbdf9534",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node name:  x\n",
      "Node type:  placeholder\n",
      "Node target:  x\n",
      "Input to this node []\n",
      "Users of this node:  {mod_0: None}\n",
      "Node name:  mod_0\n",
      "Node type:  call_module\n",
      "Node target:  mod.0\n",
      "Input to this node [x]\n",
      "Users of this node:  {mod_1: None}\n",
      "Node name:  mod_1\n",
      "Node type:  call_module\n",
      "Node target:  mod.1\n",
      "Input to this node [mod_0]\n",
      "Users of this node:  {mod_2: None}\n",
      "Node name:  mod_2\n",
      "Node type:  call_module\n",
      "Node target:  mod.2\n",
      "Input to this node [mod_1]\n",
      "Users of this node:  {mod_3: None}\n",
      "Node name:  mod_3\n",
      "Node type:  call_module\n",
      "Node target:  mod.3\n",
      "Input to this node [mod_2]\n",
      "Users of this node:  {mod_4: None}\n",
      "Node name:  mod_4\n",
      "Node type:  call_module\n",
      "Node target:  mod.4\n",
      "Input to this node [mod_3]\n",
      "Users of this node:  {mod_5: None}\n",
      "Node name:  mod_5\n",
      "Node type:  call_module\n",
      "Node target:  mod.5\n",
      "Input to this node [mod_4]\n",
      "Users of this node:  {mod_6: None}\n",
      "Node name:  mod_6\n",
      "Node type:  call_module\n",
      "Node target:  mod.6\n",
      "Input to this node [mod_5]\n",
      "Users of this node:  {mod_7: None}\n",
      "Node name:  mod_7\n",
      "Node type:  call_module\n",
      "Node target:  mod.7\n",
      "Input to this node [mod_6]\n",
      "Users of this node:  {mod_8: None}\n",
      "Node name:  mod_8\n",
      "Node type:  call_module\n",
      "Node target:  mod.8\n",
      "Input to this node [mod_7]\n",
      "Users of this node:  {mod_9: None}\n",
      "Node name:  mod_9\n",
      "Node type:  call_module\n",
      "Node target:  mod.9\n",
      "Input to this node [mod_8]\n",
      "Users of this node:  {mod_10: None}\n",
      "Node name:  mod_10\n",
      "Node type:  call_module\n",
      "Node target:  mod.10\n",
      "Input to this node [mod_9]\n",
      "Users of this node:  {mod_11: None}\n",
      "Node name:  mod_11\n",
      "Node type:  call_module\n",
      "Node target:  mod.11\n",
      "Input to this node [mod_10]\n",
      "Users of this node:  {mod_12: None}\n",
      "Node name:  mod_12\n",
      "Node type:  call_module\n",
      "Node target:  mod.12\n",
      "Input to this node [mod_11]\n",
      "Users of this node:  {mod_13: None}\n",
      "Node name:  mod_13\n",
      "Node type:  call_module\n",
      "Node target:  mod.13\n",
      "Input to this node [mod_12]\n",
      "Users of this node:  {mod_14: None}\n",
      "Node name:  mod_14\n",
      "Node type:  call_module\n",
      "Node target:  mod.14\n",
      "Input to this node [mod_13]\n",
      "Users of this node:  {mod_15: None}\n",
      "Node name:  mod_15\n",
      "Node type:  call_module\n",
      "Node target:  mod.15\n",
      "Input to this node [mod_14]\n",
      "Users of this node:  {mod_16: None}\n",
      "Node name:  mod_16\n",
      "Node type:  call_module\n",
      "Node target:  mod.16\n",
      "Input to this node [mod_15]\n",
      "Users of this node:  {mod_17: None}\n",
      "Node name:  mod_17\n",
      "Node type:  call_module\n",
      "Node target:  mod.17\n",
      "Input to this node [mod_16]\n",
      "Users of this node:  {mod_18: None}\n",
      "Node name:  mod_18\n",
      "Node type:  call_module\n",
      "Node target:  mod.18\n",
      "Input to this node [mod_17]\n",
      "Users of this node:  {mod_19: None}\n",
      "Node name:  mod_19\n",
      "Node type:  call_module\n",
      "Node target:  mod.19\n",
      "Input to this node [mod_18]\n",
      "Users of this node:  {output: None}\n",
      "Node name:  output\n",
      "Node type:  output\n",
      "Node target:  output\n",
      "Input to this node [mod_19]\n",
      "Users of this node:  {}\n"
     ]
    }
   ],
   "source": [
    "profiler_example = GraphProfiler(module=TT_nn_graph)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:01:38.610127Z",
     "start_time": "2024-03-17T16:01:38.597686Z"
    }
   },
   "id": "1455232e555b6642",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode       name    target    args       kwargs\n",
      "-----------  ------  --------  ---------  --------\n",
      "placeholder  x       x         ()         {}\n",
      "call_module  mod_0   mod.0     (x,)       {}\n",
      "call_module  mod_1   mod.1     (mod_0,)   {}\n",
      "call_module  mod_2   mod.2     (mod_1,)   {}\n",
      "call_module  mod_3   mod.3     (mod_2,)   {}\n",
      "call_module  mod_4   mod.4     (mod_3,)   {}\n",
      "call_module  mod_5   mod.5     (mod_4,)   {}\n",
      "call_module  mod_6   mod.6     (mod_5,)   {}\n",
      "call_module  mod_7   mod.7     (mod_6,)   {}\n",
      "call_module  mod_8   mod.8     (mod_7,)   {}\n",
      "call_module  mod_9   mod.9     (mod_8,)   {}\n",
      "call_module  mod_10  mod.10    (mod_9,)   {}\n",
      "call_module  mod_11  mod.11    (mod_10,)  {}\n",
      "call_module  mod_12  mod.12    (mod_11,)  {}\n",
      "call_module  mod_13  mod.13    (mod_12,)  {}\n",
      "call_module  mod_14  mod.14    (mod_13,)  {}\n",
      "call_module  mod_15  mod.15    (mod_14,)  {}\n",
      "call_module  mod_16  mod.16    (mod_15,)  {}\n",
      "call_module  mod_17  mod.17    (mod_16,)  {}\n",
      "call_module  mod_18  mod.18    (mod_17,)  {}\n",
      "call_module  mod_19  mod.19    (mod_18,)  {}\n",
      "output       output  output    (mod_19,)  {}\n"
     ]
    }
   ],
   "source": [
    "# get the node definitions\n",
    "profiler_example.module.graph.print_tabular()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:01:46.247465Z",
     "start_time": "2024-03-17T16:01:46.239085Z"
    }
   },
   "id": "67e666c155990bf4",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    batch = torch.randn(10, dim).to(mps_device)\n",
    "    profiler_example.run(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:10:26.988589Z",
     "start_time": "2024-03-17T16:10:26.957365Z"
    }
   },
   "id": "452a5576dee1d05f",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{x: [0.0003540515899658203,\n  0.00014090538024902344,\n  1.5020370483398438e-05,\n  1.2159347534179688e-05,\n  1.0967254638671875e-05,\n  1.3113021850585938e-05,\n  1.0967254638671875e-05,\n  7.152557373046875e-06,\n  8.821487426757812e-06,\n  9.059906005859375e-06,\n  6.9141387939453125e-06],\n mod_0: [0.2624201774597168,\n  0.001909017562866211,\n  0.0002300739288330078,\n  0.00028896331787109375,\n  0.00015211105346679688,\n  0.00016617774963378906,\n  0.00013589859008789062,\n  0.000102996826171875,\n  0.00013017654418945312,\n  9.799003601074219e-05,\n  0.00011277198791503906],\n mod_1: [0.041297197341918945,\n  0.0005528926849365234,\n  9.703636169433594e-05,\n  9.918212890625e-05,\n  8.797645568847656e-05,\n  0.00010180473327636719,\n  9.179115295410156e-05,\n  4.982948303222656e-05,\n  6.29425048828125e-05,\n  5.817413330078125e-05,\n  5.626678466796875e-05],\n mod_2: [0.00026488304138183594,\n  0.0001728534698486328,\n  9.608268737792969e-05,\n  8.606910705566406e-05,\n  8.916854858398438e-05,\n  8.702278137207031e-05,\n  7.915496826171875e-05,\n  6.031990051269531e-05,\n  6.890296936035156e-05,\n  5.412101745605469e-05,\n  6.198883056640625e-05],\n mod_3: [9.894371032714844e-05,\n  9.298324584960938e-05,\n  6.318092346191406e-05,\n  6.818771362304688e-05,\n  5.698204040527344e-05,\n  6.008148193359375e-05,\n  6.4849853515625e-05,\n  4.601478576660156e-05,\n  4.601478576660156e-05,\n  4.100799560546875e-05,\n  5.1021575927734375e-05],\n mod_4: [8.106231689453125e-05,\n  8.988380432128906e-05,\n  8.821487426757812e-05,\n  7.319450378417969e-05,\n  7.605552673339844e-05,\n  7.081031799316406e-05,\n  9.012222290039062e-05,\n  5.91278076171875e-05,\n  6.794929504394531e-05,\n  5.2928924560546875e-05,\n  6.008148193359375e-05],\n mod_5: [7.915496826171875e-05,\n  6.985664367675781e-05,\n  6.29425048828125e-05,\n  5.125999450683594e-05,\n  5.2928924560546875e-05,\n  5.6743621826171875e-05,\n  5.1975250244140625e-05,\n  4.506111145019531e-05,\n  4.410743713378906e-05,\n  3.981590270996094e-05,\n  4.601478576660156e-05],\n mod_6: [8.606910705566406e-05,\n  7.82012939453125e-05,\n  8.988380432128906e-05,\n  6.818771362304688e-05,\n  7.295608520507812e-05,\n  7.486343383789062e-05,\n  7.295608520507812e-05,\n  6.29425048828125e-05,\n  5.602836608886719e-05,\n  5.817413330078125e-05,\n  5.507469177246094e-05],\n mod_7: [6.890296936035156e-05,\n  7.319450378417969e-05,\n  6.008148193359375e-05,\n  4.887580871582031e-05,\n  5.2928924560546875e-05,\n  5.602836608886719e-05,\n  4.7206878662109375e-05,\n  4.506111145019531e-05,\n  4.696846008300781e-05,\n  4.029273986816406e-05,\n  4.38690185546875e-05],\n mod_8: [6.699562072753906e-05,\n  7.700920104980469e-05,\n  7.987022399902344e-05,\n  6.604194641113281e-05,\n  6.580352783203125e-05,\n  7.510185241699219e-05,\n  6.127357482910156e-05,\n  6.985664367675781e-05,\n  6.198883056640625e-05,\n  5.2928924560546875e-05,\n  5.6743621826171875e-05],\n mod_9: [6.008148193359375e-05,\n  7.724761962890625e-05,\n  6.103515625e-05,\n  4.696846008300781e-05,\n  5.1021575927734375e-05,\n  5.2928924560546875e-05,\n  6.198883056640625e-05,\n  4.506111145019531e-05,\n  4.1961669921875e-05,\n  4.00543212890625e-05,\n  4.100799560546875e-05],\n mod_10: [8.487701416015625e-05,\n  8.678436279296875e-05,\n  8.0108642578125e-05,\n  6.699562072753906e-05,\n  7.486343383789062e-05,\n  7.724761962890625e-05,\n  7.987022399902344e-05,\n  5.888938903808594e-05,\n  5.91278076171875e-05,\n  5.5789947509765625e-05,\n  5.602836608886719e-05],\n mod_11: [6.389617919921875e-05,\n  6.318092346191406e-05,\n  0.0005900859832763672,\n  5.2928924560546875e-05,\n  5.602836608886719e-05,\n  5.698204040527344e-05,\n  6.794929504394531e-05,\n  4.100799560546875e-05,\n  4.887580871582031e-05,\n  4.291534423828125e-05,\n  4.887580871582031e-05],\n mod_12: [9.107589721679688e-05,\n  9.012222290039062e-05,\n  0.00016617774963378906,\n  5.984306335449219e-05,\n  8.106231689453125e-05,\n  8.0108642578125e-05,\n  8.082389831542969e-05,\n  5.3882598876953125e-05,\n  6.008148193359375e-05,\n  5.2928924560546875e-05,\n  5.888938903808594e-05],\n mod_13: [6.604194641113281e-05,\n  6.175041198730469e-05,\n  6.198883056640625e-05,\n  4.7206878662109375e-05,\n  5.0067901611328125e-05,\n  5.340576171875e-05,\n  5.3882598876953125e-05,\n  4.1961669921875e-05,\n  4.291534423828125e-05,\n  4.00543212890625e-05,\n  4.1961669921875e-05],\n mod_14: [7.915496826171875e-05,\n  7.200241088867188e-05,\n  0.00023293495178222656,\n  6.29425048828125e-05,\n  7.700920104980469e-05,\n  8.106231689453125e-05,\n  8.20159912109375e-05,\n  5.412101745605469e-05,\n  5.888938903808594e-05,\n  6.008148193359375e-05,\n  6.604194641113281e-05],\n mod_15: [5.793571472167969e-05,\n  6.389617919921875e-05,\n  0.0002639293670654297,\n  4.696846008300781e-05,\n  4.982948303222656e-05,\n  5.0067901611328125e-05,\n  4.696846008300781e-05,\n  4.100799560546875e-05,\n  4.100799560546875e-05,\n  4.482269287109375e-05,\n  4.506111145019531e-05],\n mod_16: [7.700920104980469e-05,\n  8.392333984375e-05,\n  0.00027489662170410156,\n  6.818771362304688e-05,\n  6.914138793945312e-05,\n  7.319450378417969e-05,\n  7.128715515136719e-05,\n  5.3882598876953125e-05,\n  6.508827209472656e-05,\n  5.412101745605469e-05,\n  5.5789947509765625e-05],\n mod_17: [5.0067901611328125e-05,\n  7.295608520507812e-05,\n  0.0001499652862548828,\n  4.696846008300781e-05,\n  5.1975250244140625e-05,\n  5.030632019042969e-05,\n  4.57763671875e-05,\n  4.100799560546875e-05,\n  4.1961669921875e-05,\n  4.00543212890625e-05,\n  4.029273986816406e-05],\n mod_18: [6.103515625e-05,\n  9.083747863769531e-05,\n  0.0002880096435546875,\n  6.508827209472656e-05,\n  7.104873657226562e-05,\n  7.319450378417969e-05,\n  7.510185241699219e-05,\n  6.198883056640625e-05,\n  6.198883056640625e-05,\n  5.1975250244140625e-05,\n  5.2928924560546875e-05],\n mod_19: [4.7206878662109375e-05,\n  5.507469177246094e-05,\n  0.0005209445953369141,\n  5.0067901611328125e-05,\n  5.888938903808594e-05,\n  5.793571472167969e-05,\n  4.6253204345703125e-05,\n  4.100799560546875e-05,\n  4.506111145019531e-05,\n  4.410743713378906e-05,\n  4.00543212890625e-05],\n output: [1.0967254638671875e-05,\n  1.1205673217773438e-05,\n  8.106231689453125e-06,\n  5.0067901611328125e-06,\n  5.245208740234375e-06,\n  5.0067901611328125e-06,\n  3.814697265625e-06,\n  4.0531158447265625e-06,\n  4.0531158447265625e-06,\n  4.0531158447265625e-06,\n  2.6226043701171875e-06]}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiler_example.runtimes_sec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-17T16:10:32.285105Z",
     "start_time": "2024-03-17T16:10:32.264575Z"
    }
   },
   "id": "65e62439bc6371dd",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "96465a1c6b5de7cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
